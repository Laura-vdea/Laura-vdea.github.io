VEDA 바로가기 : `www.vedacademy.co.kr`
VEDA(한화비전 아카데미) 영상으로 확인하기 : `https://url.kr/zy9afd`
본 후기는 VEDA(한화비전 아카데미) 첫번째 학습 기록으로 작성되었습니다.
교육기간 : `2024.07.15~2024.12.16`

------- 
- 작성일 : 2024-10-06
- 작성자 : 박지우
- 수업할 때에 사용한 언어 : C/C++
- 포스팅 목적 : 11주 차시의 한화비전 베다 수업 회고록

---

![](https://velog.velcdn.com/images/laura_vdea/post/bcd5298c-6c85-409e-a633-f92e54247c85/image.png)


------

# 목차

1. [서론](#0-서론)
2. [wiringpi를 이용한 LED 제어 및 음악재생](#1-wiringpi를-이용한-led-제어-및-음악-재생)
3. [이미지 특장점 추출](#2-opencv-기반-이미지-특징점-추출)
3. [OpenCV를 이용한 얼굴 및 눈 인식](#3-opencv를-이용한-얼굴-및-눈-인식)
4. [GStreamer를 사용한 서버와 클라이언트 스트리밍](#4-gstreamer를-사용한-서버와-클라이언트-스트리밍)
5. [마무리](#5-마무리)

------------------------

## 0. 서론
 이번 주 수업에서는 라즈베리파이를 활용한 임베디드 시스템 개발 실습을 중점적으로 다뤄봤다. 
실습은 크게 WiringPi를 이용한 하드웨어 제어, OpenCV를 활용한 얼굴 및 눈 인식, 그리고 GStreamer를 사용한 서버-클라이언트 영상 스트리밍으로 구성되어있으며 각 코드들은 하드웨어와 소프트웨어가 어떻게 연동되어 동작하는지에 대한 심도 있는 이해를 할 수 있었던 시간이 되어 주었다.

## 1. WiringPi를 이용한 LED 제어 및 음악 재생
 이번 실습의 첫 번째 주제는 라즈베리파이의 GPIO 핀을 제어하는 것이었다. `WiringPi` 라이브러리를 이용하여 스위치, 조도 센서, LED, 스피커를 제어하는 코드를 작성하였으며, 특히 스레드와 뮤텍스를 사용하여 동시성 제어와 안정적인 상태 관리를 구현하였다.

### LED 및 음악 재생
 조도 센서가 어두운 환경을 감지하면 LED를 켜고, 스피커로 간단한 멜로디를 재생하는 프로그램을 만들었다. 
스위치를 통해 전체 시스템을 끄고 켤 수 있는 기능도 구현할 수 있었다.

```
void* switchControl(void* arg) {
    while (1) {
        int swState = digitalRead(SW);
        pthread_mutex_lock(&lock);
        if (swState == HIGH && prevSwState == LOW) {
            isSwitchedOff = !isSwitchedOff;
            if (isSwitchedOff) {
                isRunning = 0;
                digitalWrite(LED, LOW);
                softToneWrite(SPKR, 0);
            } else {
                isRunning = 1;
            }
        }
        pthread_mutex_unlock(&lock);
        prevSwState = swState;
        delay(100);
    }
}
```

### 음악 재생과 뮤텍스 동시성 처리 설명
이 코드에서 **뮤텍스(pthread_mutex)** 를 사용한 이유는 여러 스레드가 동시에 LED 상태와 음악 재생을 제어할 때 발생할 수 있는 데이터 경쟁을 방지하기 위해서 였다. 
특히, 스위치가 눌리거나 조도 센서가 활성화되면 LED와 음악을 동시에 제어해야 하는데, 이 과정에서 뮤텍스를 사용하여 동기화하고 있다.

#### 1.1. 뮤텍스를 통한 동시성 제어
뮤텍스(`pthread_mutex_t`)는 여러 스레드가 동시에 공유 자원에 접근할 때 이를 직렬화하여 한 번에 한 스레드만 해당 자원에 접근할 수 있도록 보장을 해줄 수 있다. 

이 코드에서 뮤텍스는 두 가지 역할을 한다.

**스레드 간의 데이터 보호**
LED와 음악 상태(`isRunning` 및 `isSwitchedOff`)를 변경하거나 확인할 때, 이를 보호하여 다른 스레드가 동시에 값을 변경하지 못하도록 한다.
**LED와 음악 제어 동기화**
스위치 상태에 따라 음악 재생과 LED가 동시에 변경되어야 하는 상황에서, 뮤텍스 잠금을 통해 두 가지 작업이 안전하게 처리되도록 보장한다.

#### 1.2. 음악 재생에서의 뮤텍스 활용
음악 재생(`musicPlay` 함수)에서는 스레드가 음악을 재생하는 중간에 스위치가 눌려서 시스템이 꺼지면, 바로 음악 재생을 멈출 수 있도록 뮤텍스를 사용하였다.

```
void musicPlay() {
    for (int i = 0; i < TOTAL; ++i) {
        pthread_mutex_lock(&lock);  // 뮤텍스 잠금
        if (!isRunning || isSwitchedOff) {  // 시스템이 꺼졌거나 스위치로 꺼졌다면 중지
            pthread_mutex_unlock(&lock);  // 뮤텍스 잠금 해제
            break;
        }
        pthread_mutex_unlock(&lock);  // 뮤텍스 잠금 해제
        softToneWrite(SPKR, notes[i]); // 음계 재생
    }
}
```

**뮤텍스 잠금 (pthread_mutex_lock)**
음악 재생 중 시스템이 종료되었거나 스위치가 꺼졌는지 확인하기 위해 상태 플래그 isRunning과 isSwitchedOff를 보호한다.
**뮤텍스 잠금 해제 (pthread_mutex_unlock)**
상태 확인 후, 뮤텍스를 즉시 해제하여 다른 스레드가 상태를 변경할 수 있도록 허용한다.

#### 1.3. 스위치 제어와 동시성 처리
스위치가 눌렸을 때 LED와 음악을 동시에 제어하는 기능을 구현하였다.
뮤텍스를 사용하여 LED와 음악을 동시에 끄거나 켤 수 있도록 동기화하고 있다.

```
void* switchControl(void* arg) {
    while (1) {
        int swState = digitalRead(SW);  // 스위치 상태 읽기
        if (swState == HIGH && prevSwState == LOW) {  // 스위치가 눌린 경우
            pthread_mutex_lock(&lock);  // 뮤텍스 잠금
            isSwitchedOff = !isSwitchedOff;  // 스위치로 시스템을 끄고 켜는 상태 토글
            if (isSwitchedOff) {
                isRunning = 0;  // LED와 음악을 중지
                digitalWrite(LED, LOW);  // LED 끄기
                softToneWrite(SPKR, 0);  // 음악 끄기
            } else {
                isRunning = 1;  // 시스템 다시 켜기
            }
            pthread_mutex_unlock(&lock);  // 뮤텍스 잠금 해제
        }
        prevSwState = swState;  // 스위치 상태 업데이트
        delay(100);  // 짧은 지연
    }
    return NULL;
}
```
**- 뮤텍스 잠금 (pthread_mutex_lock)**
스위치가 눌릴 때, 시스템 상태를 변경하는 동안 다른 스레드가 동시에 상태를 읽거나 변경하지 못하도록 한다.
**- 뮤텍스 잠금 해제 (pthread_mutex_unlock)**
스위치로 LED와 음악 상태를 변경한 후, 뮤텍스를 해제하여 다른 스레드가 계속 작업을 수행할 수 있도록 허용한다.

#### 1.4. 메인 제어 루프에서의 동기화
메인 제어 루프에서는 조도 센서의 상태에 따라 LED와 음악을 제어하는데, 여기서도 뮤텍스를 사용하여 스레드 간 동시 접근을 제어하고 있다.

```
if (!isSwitchedOff) {
    if (cdsState == HIGH) {  // 조도 센서가 빛을 감지하면 LED와 음악 켜기
        isRunning = 1;
        digitalWrite(LED, HIGH);  // LED 켜기
        pthread_mutex_unlock(&lock);  // 뮤텍스 잠금 해제
        musicPlay();  // 음악 재생
    } else {  // 조도 센서가 빛을 감지하지 못하면 LED와 음악 끄기
        isRunning = 0;
        digitalWrite(LED, LOW);   // LED 끄기
        softToneWrite(SPKR, 0);   // 음악 끄기
        pthread_mutex_unlock(&lock);  // 뮤텍스 잠금 해제
    }
}
```

### 결론
 라즈베리파이를 이용해 조도 센서와 스위치를 활용한 LED 및 음악 제어 시스템을 구축하였다. 멀티스레드와 뮤텍스를 사용하여 안전하고 동시성 제어가 가능한 시스템을 만들었다. 또한 여기에 뮤텍스를 활용하여서 스위치 조작, 조도 센서 감지 및 음악 재생간의 동시성을 제어할 수 있었다.
 
## 2. OpenCV 기반 이미지 특징점 추출
 ![](https://velog.velcdn.com/images/laura_vdea/post/18dc9b5d-2d28-4d75-a7a7-49ee023e9e9b/image.png)
 
 OpenCV를 사용하여 두 이미지 간의 특징점을 추출하고, 매칭하는 과정을 수행하는 수업이었다. 
RANSAC을 사용해 두 이미지 간의 Homography(호모그래피) 변환을 계산하여, 첫 번째 이미지의 객체를 두 번째 이미지에서 각각 매칭점을 대조하여 찾는 코드다.

### 2.1. 이미지 읽기
두 개의 이미지를 **Grayscale(흑백)** 로 읽어들인다. 이미지가 제대로 로드되지 않으면 에러를 출력하고 종료한다.
```
Mat img1 = imread("/home/pi/project/test/image/model3.jpg", IMREAD_GRAYSCALE);
Mat img2 = imread("/home/pi/project/test/image/scene.jpg", IMREAD_GRAYSCALE);

assert(img1.data && img2.data);
```

### 2.2. SIFT를 이용한 특징점 검출
SIFT(Scale-Invariant Feature Transform) 알고리즘을 사용해 두 이미지에서 **KeyPoint(특징점)** 을 추출한다.
추출한 특징점을 이미지에 그려 표시한다.

```
Ptr<SIFT> detector = SIFT::create(0.3);
std::vector<KeyPoint> keypoint1, keypoint2;
detector->detect(img1, keypoint1);
detector->detect(img2, keypoint2);
```

### 2.3. 특징점 기술자 추출 및 매칭
추출한 특징점을 바탕으로 SIFT Descriptor를 계산하여 두 이미지 간의 FlannBasedMatcher를 사용해 매칭한다.
각 매칭 결과의 거리를 비교하여 **좋은 매칭(Good Match)** 을 필터링한다.

```
Ptr<SIFT> extractor = SIFT::create();
Mat descriptor1, descriptor2;
extractor->compute(img1, keypoint1, descriptor1);
extractor->compute(img2, keypoint2, descriptor2);

FlannBasedMatcher matcher;
std::vector<DMatch> matches;
matcher.match(descriptor1, descriptor2, matches);
```

### 2.4. 매칭 결과 그리기
두 이미지 간의 Good Match만을 그려서 시각적으로 매칭 결과를 확인할 수 있도록 한다.
```
std::vector<DMatch> goodMatch;
// 매칭 결과 중 최소 거리 기준으로 좋은 매칭만 선택
for (int i = 0; i < descriptor1.rows; i++) {
    if (matches[i].distance <= max(2 * mind, 0.02)) {
        goodMatch.push_back(matches[i]);
    }
}

Mat img_match;
drawMatches(img1, keypoint1, img2, keypoint2, goodMatch, img_match);
imshow("Matching Result", img_match);
```

### 2.5. Homography 계산 및 객체 위치 확인
`Good Match`로부터 특징점 좌표를 수집하고, RANSAC 알고리즘을 이용해 Homography를 계산한다.
이를 통해 첫 번째 이미지의 코너 좌표를 변환하여 두 번째 이미지에서 해당 객체의 위치를 찾고, 그 위치를 사각형으로 표시한다.

```
Mat H = findHomography(model_pt, scene_pt, RANSAC);

std::vector<Point2f> model_corner(4);
model_corner[0] = Point(0, 0);
model_corner[1] = Point(img1.cols, 0);
model_corner[2] = Point(img1.cols, img1.rows);
model_corner[3] = Point(0, img1.rows);

std::vector<Point2f> scene_corner(4);
perspectiveTransform(model_corner, scene_corner, H);

// 두 번째 이미지에서 첫 번째 이미지의 객체 위치 표시
line(img_match, scene_corner[0] + Point2f(img1.cols, 0), scene_corner[1] + Point2f(img1.cols, 0), RED, 3);
```

### 2.6. 결과 시각화
최종적으로 두 이미지 간의 특징점 매칭 결과와 호모그래피 변환으로 찾은 객체 위치를 표시한 이미지를 화면에 출력한다.

```
imshow("Matching Result", img_match);
imshow("Homography Result", img_match);
```

### 결론
이 코드는 SIFT 알고리즘을 이용해 이미지의 특징점을 추출하고, FlannBasedMatcher를 사용해 두 이미지 간의 유사한 점을 매칭합니다. 그런 다음, RANSAC을 이용한 호모그래피 변환으로 객체의 위치를 찾아 시각적으로 표시합니다.

## 3. OpenCV를 이용한 얼굴 및 눈 인식
 OpenCV 라이브러리를 이용한 실시간 얼굴 및 눈 인식 실습을 진행하였다. 처음에는 어려운 것이 아닐까 걱정했지만 라이브러리의 힘을 빌려서 어렵지 않게 할 수 있었다. 
이 과정에서는 카메라로부터 입력받은 영상을 처리하여 얼굴과 눈을 탐지하고, 이를 영상에 표시하는 시스템을 구축하였다.

### 얼굴 및 눈 인식
 OpenCV의 CascadeClassifier를 사용하여 얼굴 및 눈을 탐지하였으며, 이를 영상에 표시하는 기능을 구현하였다.	
 
 ```
 void FaceAndEyeDetect(Mat img) {
    std::vector<Rect> face_pos;
    face.detectMultiScale(gray, face_pos, 1.1, 2, 0 | CASCADE_SCALE_IMAGE, Size(10, 10));

    for (int i = 0; i < face_pos.size(); i++) {
        rectangle(img, face_pos[i], Scalar(255, 0, 0), 2);
        std::vector<Rect> eye_pos;
        Mat roi = gray(face_pos[i]);
        eye.detectMultiScale(roi, eye_pos, 1.1, 2, 0 | CASCADE_SCALE_IMAGE, Size(10, 10));
        for (int j = 0; j < eye_pos.size(); j++) {
            Point center(face_pos[i].x + eye_pos[j].x + eye_pos[j].width / 2, face_pos[i].y + eye_pos[j].y + eye_pos[j].height * 0.5);
            circle(img, center, radius, Scalar(0, 255, 0), 2);
        }
    }
}
```

### 결론
카메라로부터 실시간으로 얼굴과 눈을 탐지하여 표시할 수 있는 시스템을 구현하였다. 이 시스템은 얼굴 및 눈 탐지 정확도가 중요하며, 라즈베리파이 성능에 따른 처리 속도에도 영향을 받는다.

## 4. GStreamer를 사용한 서버와 클라이언트 스트리밍
 GStreamer를 이용한 서버-클라이언트 스트리밍 시스템도 이번 주 수업에서 중요한 실습 중 하나였다. 서버는 TCP 기반으로 카메라에서 받은 영상을 스트리밍하고, 클라이언트는 이를 수신하여 재생하는 구조로 구현하였다.

### GStreamer 서버
라즈베리파이의 카메라에서 `libcamerasrc`를 이용해 영상을 받아서 `tcpserversink`를 통해 클라이언트로 전송한다.
```
void gstreamer_server() {
    gst_init(nullptr, nullptr);
    SmartPtr pipeline(gst_parse_launch("libcamerasrc ! video/x-raw,width=1280,height=720,framerate=30/1 ! jpegenc ! multipartmux ! tcpserversink host=0.0.0.0 port=5000", nullptr));
    gst_element_set_state(pipeline.get(), GST_STATE_PLAYING);
    handle_message(pipeline, bus);
}
```

### 클라이언트 비디오 캡처
클라이언트는 GStreamer를 이용해 서버로부터 비디오 스트림을 수신한다. 여기에서 중요한 부분은 라즈베리파이의 카메라 장치를 직접 제어하는 파이프라인 설정이다.

```
std::string pipeline = "libcamerasrc camera-name=/base/axi/pcie@120000/rp1/i2c@80000/ov5647@36 ! video/x-raw, width=640, height=480, format=RGB, framerate=30/1 ! videoconvert ! appsink";
VideoCapture v(pipeline, CAP_GSTREAMER);

assert(v.isOpened());

if(!v.isOpened()) {
    std::cout << "VideoCapture not opened" << std::endl;
    return -1;
}
```

### GStreamer 클라이언트
클라이언트는 `tcpclientsrc`를 통해 서버로부터 스트림을 수신하고 이를 `autovideosink`로 재생할 수 있다.

```
void gstreamer_client(const std::string& server_ip) {
    gst_init(nullptr, nullptr);
    std::string pipeline_desc = "tcpclientsrc host=" + server_ip + " port=5000 ! jpegdec ! autovideosink";
    SmartPtr pipeline(gst_parse_launch(pipeline_desc.c_str(), nullptr));
    gst_element_set_state(pipeline.get(), GST_STATE_PLAYING);
}
```

### 결과
서버는 라즈베리파이 카메라에서 영상을 실시간으로 스트리밍하고, 클라이언트는 이 스트림을 받아 재생할 수 있었습니다. 네트워크 연결에 따라 스트리밍 성능이 달라지며, GStreamer의 다양한 요소를 활용해 구현하였다.

![](https://velog.velcdn.com/images/laura_vdea/post/0487735c-8200-4489-8ec1-d1aea150551b/image.png)

![](https://velog.velcdn.com/images/laura_vdea/post/ff926443-79ac-40d7-aec8-a0612a5a32c8/image.png)


## 5. 마무리
이번 주 수업에서는 라즈베리파이를 활용한 임베디드 시스템 개발과 GPIO 제어, OpenCV를 활용한 얼굴 인식, GStreamer를 사용한 스트리밍 시스템까지 다양한 주제를 다루었습니다. 각 실습을 통해 하드웨어와 소프트웨어의 밀접한 연계와 실제 임베디드 시스템 환경에서의 동작을 학습할 수 있었습니다.

이번 주는 임베디드 시스템 개발을 집중적으로 다루면서 라즈베리파이를 활용한 다양한 실습을 통해 하드웨어와 소프트웨어의 연계를 체감할 수 있었습니다. 특히 WiringPi를 사용한 LED 제어 및 음악 재생, OpenCV를 활용한 이미지 처리와 얼굴 인식, 그리고 GStreamer를 통한 서버-클라이언트 스트리밍 구현까지 다양한 주제들이 흥미로웠습니다.

### ✌️ 마무리 정리
**😄 Liked**
이번 주는 GPIO 제어를 통해 임베디드 시스템의 기본을 다질 수 있었고, WiringPi와 OpenCV를 사용해 실시간 하드웨어 및 영상 처리를 직접 경험한 점이 매우 인상적이었습니다. 특히 하드웨어 제어와 멀티스레드 동기화를 통해 실시간으로 동작하는 시스템을 만들어보며, 실무에서의 활용도를 높일 수 있었습니다.

또한 GStreamer를 활용한 영상 스트리밍 기능 구현은 서버와 클라이언트 간의 통신을 이해하고 실제 구현까지 진행할 수 있어 유익한 시간이었습니다. 한화비전 베다에서의 교육을 통해 실무와 밀접한 프로젝트 경험을 쌓을 수 있었습니다.

**😄 Learned**
이번 주 학습의 핵심은 라즈베리파이와 WiringPi를 통해 GPIO 제어를 직접 경험하면서, 하드웨어와 소프트웨어 간의 연동이 중요한 임베디드 시스템의 기초를 다진 것입니다. 특히 OpenCV를 활용해 영상 처리를 실시간으로 구현하고, GStreamer를 통해 스트리밍 시스템을 구축하는 과정에서 임베디드 개발과 네트워크 프로그래밍의 기본을 이해하게 되었습니다.

또한 스레드 및 뮤텍스를 활용해 동시성 제어를 구현하며, 시스템의 안정성을 높이는 기술을 실습할 수 있었습니다. 이를 통해 실제 임베디드 시스템에서 자주 발생하는 문제들을 해결하는 경험을 쌓을 수 있었고, 앞으로의 프로젝트에서도 이를 응용할 수 있는 자신감을 가지게 되었습니다.

**😄 Lacked**
다소 아쉬운 점은 라즈베리파이의 더 복잡한 기능들을 다루지 못한 부분입니다. 예를 들어 하드웨어 가속이나 고급 센서 제어와 같은 내용은 시간이 부족해 심도 있게 다루지 못했지만, 다음 학습에서 이러한 부분을 보완할 계획입니다. 이를 통해 실무에 더욱 필요한 기술들을 더 많이 습득하고자 합니다.

**😄 Longed for**
다음 주에는 현재 배운 GPIO 제어와 영상 처리 기술을 발전시켜 더 큰 프로젝트에 도전하고 싶습니다. 특히 Qt 프로젝트를 포함해 하드웨어 가속, 센서 제어와 같은 고급 기능을 다루면서 임베디드 개발의 실무 경험을 쌓아가고자 합니다. 또한, 이번 주에 배운 스트리밍 시스템을 발전시켜 네트워크 관련 프로젝트에도 응용하고 싶습니다.

취업 준비에 있어서는, 실무에서 요구되는 기술들을 특강에서 배운 내용을 바탕으로 꾸준히 보완해 나가며 프로젝트와 경험을 통해 실력을 증진시킬 계획입니다.

### ✌️ 회고 및 다짐
이번 주는 라즈베리파이를 통한 임베디드 시스템 개발과 실시간 영상 처리 기술을 익힐 수 있던 뜻깊은(?) 시간이었습니다. 실무와 밀접하게 연계된 특강을 통해, 향후 취업 준비에 필요한 방향성도 더욱 명확해졌습니다. 앞으로도 꾸준히 학습하고 실습하며, 실무에서 요구하는 프로젝트 경험을 쌓아 나갈 것입니다.

앞으로도 라즈베리파이와 같은 임베디드 플랫폼을 활용해 더 복잡한 프로젝트를 도전하고, 임베디드 시스템 개발에 필요한 핵심 기술들을 계속해서 습득해 나가겠습니다.

----------

VEDA 바로가기 : `www.vedacademy.co.kr`
VEDA(한화비전 아카데미) 영상으로 확인하기 : `https://url.kr/zy9afd`
본 후기는 VEDA(한화비전 아카데미) 첫번째 학습 기록으로 작성되었습니다.
교육기간 : `2024.07.15~2024.12.16`


